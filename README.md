# Sign_Language_Detection ğŸ–ï¸

Hey everyone,

This is a Real-Time Sign **Language Detection System** built using Python, OpenCV, Mediapipe, and scikit-learn. The aim is to recognize hand gestures via webcam and map them to sign language gestures in real time.

 # How it works ğŸ§ 
Iâ€™ve used Mediapipe for detecting hand landmarks. With OpenCV, I created a pipeline to capture and label gesture data. Then, using scikit-learn, I trained a classification model that identifies gestures based on those landmarks.

# Data Collection ğŸ“
Data is captured using your webcam with OpenCV, and each gesture is labeled for training. You can customize this to collect your own gestures as well!

# Model Training ğŸ§ª
The labeled gesture data is used to train a simple yet effective machine learning model. You can find the code in the .ipynb and .py files.


Thanks for checking it out! ğŸ™Œ

